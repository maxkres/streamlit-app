{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Murcha1990/ML_AI25/blob/main/Hometasks/Base/HW1_Regression_with_inference_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsPer4g5FgRB"
      },
      "source": [
        "# **Домашнее задание №1 (base). Часть 1**\n",
        "\n",
        "В этом домашнем задании вам будет необходимо:\n",
        "*  обучить модель регрессии для предсказания стоимости автомобилей;\n",
        "\n",
        "**Максимальная оценка за дз**\n",
        "> Оценка за первую часть домашки = $min(\\text{ваш балл}, 7)$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBxaROjhnExd"
      },
      "source": [
        "**Примечание**\n",
        "\n",
        "В каждой части оцениваются как код, **так и ответы на вопросы.**\n",
        "\n",
        "Если нет одного и/или другого, то часть баллов за соответствующее задание снимается."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKXD33FOsnGd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import seaborn as sns\n",
        "from IPython.display import display\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAzbEw1ctU4f"
      },
      "source": [
        "Давайте зафиксируем важный момент.\n",
        "\n",
        "**Задание 0 (0 баллов).**\n",
        "Изучите и ответье на вопрос: для чего фиксируем сиды в домашках?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNtt7mM9eAY4"
      },
      "source": [
        "**Ответ:** Чтобы результаты были воспроизводимы и не менялись при каждом перезапуске ноутбука. Ассистенту будет проще проверять домашки с одинаковым сидом, на тех же данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykzSVgN7q-xZ"
      },
      "source": [
        "# **Часть 1 | EDA и визуализация**\n",
        "\n",
        "Первая часть состоит из классических шагов EDA:\n",
        "\n",
        "- Базовый EDA и обработка признаков (2.5 балла)\n",
        "- Визуализации признаков и их анализ (1 балл)\n",
        "\n",
        "Всего можно набрать 3.5 основных балла и 0.65 бонусных. Бонусные задания выделены как **Дополнительное задание/Бонус**. Вы можете выполнять их, чтобы в случае ошибок в основных задачах всё равно набрать за работу максимум. Кроме того, дополнительные задания позволяют вам углубить знания.\n",
        "\n",
        "Призываем активно использовать их!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-4bM9CKAtCj"
      },
      "source": [
        "## **Простейший EDA и обработка признаков (2.5 балла)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FniH6eCGFSi_",
        "outputId": "660345f0-8402-459b-a9c7-021d5472556d"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('https://raw.githubusercontent.com/Murcha1990/MLDS_ML_2022/main/Hometasks/HT1/cars_train.csv')\n",
        "df_test = pd.read_csv('https://raw.githubusercontent.com/Murcha1990/MLDS_ML_2022/main/Hometasks/HT1/cars_test.csv')\n",
        "\n",
        "print(\"Train data shape:\", df_train.shape)\n",
        "print(\"Test data shape: \", df_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPe2gY1agYfp"
      },
      "source": [
        "### **Задание 1 (0.5 балла)**\n",
        "\n",
        "Вы уже встречались с pandas в первой половине семестра. Теперь будем постоянно (кроме некоторых случаев) использовать его для анализа данных и наслаивать навыки. Выполните операции, направленные на практику основных действий с `pandas`:\n",
        "\n",
        "**0.1 балла**\n",
        "- [ ] Отобразите 30 случайных строк тренировочного датасета.\n",
        "- [ ] Отобразите первые 5 и последние 5 объектов тестового датасета\n",
        "- [ ] Посмотрите, есть ли в датасете пропуски. Запишите/выведите названия колонок, для которых есть пропущенные значения\n",
        "- [ ] Посмотрите, есть ли в данных явные дубликаты\n",
        "\n",
        "\n",
        "**0.2 балла**\n",
        "Ответьте на вопросы:\n",
        "- [ ] Выводы о чем можно сделать, используя случайные/верхние/нижние строки? А о чем нельзя?\n",
        "- [ ] Достаточно ли метода duplicated для анализа дубликатов? Почему?\n",
        "\n",
        "**0.15 балла**\n",
        "- [ ] Постройте дашборд, используя [ydata-profilling](https://github.com/ydataai/ydata-profiling)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Ответ:** Случайные строки показывают разнообразие данных. Верхние/нижние - порядок сортировки в источнике. Нельзя судить о статистиках распределений. duplicated() ищет только полные дубликаты строк, не учитывает частичные совпадения.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(df_train.sample(30, random_state=42))\n",
        "\n",
        "display(pd.concat([df_test.head(5), df_test.tail(5)]))\n",
        "\n",
        "display((\n",
        "    df_train.columns[df_train.isna().any()].tolist(),\n",
        "    df_test.columns[df_test.isna().any()].tolist()\n",
        "))\n",
        "\n",
        "display((\n",
        "    df_train.duplicated().sum(),\n",
        "    df_test.duplicated().sum()\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "profile = ProfileReport(df_train, title=\"Train Data Profile\", explorative=True)\n",
        "profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF6L8XVejuEe"
      },
      "source": [
        "Мы обнаружили пропуски. Давайте избавимся от них.\n",
        "\n",
        "**(0.05 балла)**\n",
        "- [ ] Заполните пропуски в столбцах медианами. Убедитесь, что после заполнения пропусков не осталось. Заполнение пропусков проводите для обоих наборов данных, если необходимо\n",
        "\n",
        "**Важно!**\n",
        "\n",
        "При заполнении пропусков и в тестовом, и тренировочном наборах данных вы определяетесь со стратегией предобработки пропущенных значений при потенциальной работе модели.\n",
        "\n",
        "Так как в теоретическом случае вы не имеете доступа к тестовой выборке, то заполняемой значение (у нас — медиана) вы считаете про *тренировочному* набору данных и им же заполняете *тестовый*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ayq_I9Pk68k"
      },
      "outputs": [],
      "source": [
        "numeric_cols = df_train.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "medians = df_train[numeric_cols].median()\n",
        "\n",
        "df_train[numeric_cols] = df_train[numeric_cols].fillna(medians)\n",
        "df_test[numeric_cols] = df_test[numeric_cols].fillna(medians)\n",
        "\n",
        "df_train.isna().sum().sum(), df_test.isna().sum().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE_ecCD7hRFV"
      },
      "source": [
        "### **Задание 2 (0.5 балла)**\n",
        "\n",
        "На прошлом шаге вы рассмотрели дубликаты. Однако дубликат может быть связан с не только полным повторением информации в нескольких строках, но и частиным. Например, объект мог был внесен в базу данных с разным значением целевой переменной. В этом шаге займемся такими дублями!\n",
        "\n",
        "**Ваши действия:**\n",
        "\n",
        "- [ ] Посмотрите, есть ли в трейне объекты с одинаковым признаковым описанием (целевую переменную следует исключить). Если есть, то сколько? (0.1 балла)\n",
        "- [ ] Отобразите такие объекты (0.15 балла)\n",
        "- [ ] Удалите повторяющиеся строки. Если при одинаковом признаковом описании цены на автомобили отличаются, то оставьте первую строку по этому автомобилю (0.15 балла)\n",
        "- [ ]  Обновите индексы строк таким образом, чтобы они шли от 0 без пропусков (0.1 балла)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkyrBlHWiGY6"
      },
      "outputs": [],
      "source": [
        "target_col = \"selling_price\"\n",
        "feature_cols = df_train.columns.drop(target_col)\n",
        "\n",
        "dup_mask = df_train.duplicated(subset=feature_cols, keep=False)\n",
        "n_dup_rows = int(dup_mask.sum())\n",
        "print(\"Дубликаты по признакам (строки):\", n_dup_rows)\n",
        "\n",
        "display(df_train.loc[dup_mask].sort_values(list(feature_cols)))\n",
        "\n",
        "df_train = (\n",
        "    df_train\n",
        "    .drop_duplicates(subset=feature_cols, keep=\"first\")\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "print(\"Итоговая форма:\", df_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "955cO__niGyz",
        "outputId": "7889666c-0dc5-4887-812c-e1c65f064e86"
      },
      "outputs": [],
      "source": [
        "assert df_train.shape == (5840, 13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sam1Pzn-iU86"
      },
      "source": [
        "Отлично! Мы избавились от маленьких и явных проблем. Теперь перейдем к более сложным недостаткам полученной таблицы.\n",
        "\n",
        "### **Задание 3 (0.25 балла)**\n",
        "\n",
        "Вы могли заметить, что с признаками ``mileage, engine, max_power и torque`` всё не очень хорошо. Они распознаются как строки (можно убедиться в этом, вызвав `data.dtypes`). Однако эти переменные не являются категориальными — они — числа. Соответственно, нужно привести их к числовому виду.\n",
        "\n",
        "**Задача :**\n",
        "* [ ] Уберите единицы измерения для признаков ``mileage, engine, max_power``.\n",
        "* [ ] Приведите тип данных к ``float``.\n",
        "* [ ] Удалите столбец ``torque``\n",
        "\n",
        "\n",
        "**Важно**\n",
        "- Все действия нужно производить над обоими датасетами — `train` и `test`.\n",
        "- Стобец ``torque`` мы удаляем для простоты. В идеальном случае, его также стоило бы предобработать."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mi1RSmFjlAm7"
      },
      "outputs": [],
      "source": [
        "cols_to_float = [\"mileage\", \"engine\", \"max_power\"]\n",
        "\n",
        "for df in (df_train, df_test):\n",
        "    for col in cols_to_float:\n",
        "        df[col] = pd.to_numeric(\n",
        "            df[col].astype(str).str.replace(r\"[^0-9.]+\", \"\", regex=True),\n",
        "            errors=\"coerce\"\n",
        "        ).astype(\"float\")\n",
        "    df.drop(columns=[\"torque\"], inplace=True, errors=\"ignore\")\n",
        "\n",
        "df_train[cols_to_float].dtypes, df_test[cols_to_float].dtypes, df_train.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r9cXKx9lDaZ"
      },
      "source": [
        "### **Задание 4 (0.1 балла)**\n",
        "\n",
        "Теперь, когда не осталось пропусков, давайте преобразуем столбцы к более подходящим типам. А именно столбцы ``engnine`` и ``seats`` к приведем к `int`.\n",
        "\n",
        "- [ ] Осуществите приведение столбцов к необходимому типу."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUT8mOQNlmlN"
      },
      "outputs": [],
      "source": [
        "cols_to_int = [\"engine\", \"seats\"]\n",
        "\n",
        "fill_vals = df_train[cols_to_int].median()\n",
        "\n",
        "for df in (df_train, df_test):\n",
        "    df[cols_to_int] = df[cols_to_int].fillna(fill_vals)\n",
        "    df[cols_to_int] = df[cols_to_int].round().astype(\"int64\")\n",
        "\n",
        "df_train[cols_to_int].dtypes, df_test[cols_to_int].dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFuQ_PsulqCs"
      },
      "source": [
        "### **Задание 5 (0.15 балла)**\n",
        "\n",
        "Отлично! Мы провели \"косметическую\" предобработку и теперь готовы сделать важный шаг в контексте анализа данных. А именно — посмотреть на статистики!\n",
        "\n",
        "**Ваша задача:**\n",
        "- [ ] Посчитайте основные статистики по числовым столбцам для трейна и теста\n",
        "- [ ] Посчитайте основные статистики по категориальным столбцам для трейна и теста\n",
        "- [ ] Сделайте вывод.\n",
        "\n",
        "**Подсказка:**\n",
        "\n",
        "Используте ``.describe()`` с нужным(и) аргументом(-ами).\n",
        "\n",
        "**Примечание:**\n",
        "\n",
        "Более корректно рассматривать статистики до заполнения пропусков и после, чтобы убедиться, что мы не внесли каких-либо серьезных сдвигов в изначальные рапсределения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYKWyjsLYQuz"
      },
      "outputs": [],
      "source": [
        "print(\"TRAIN — числовые\")\n",
        "display(df_train.describe(include=[np.number]))\n",
        "\n",
        "print(\"TRAIN — категориальные\")\n",
        "display(df_train.describe(include=[\"object\"]))\n",
        "\n",
        "print(\"TEST — числовые\")\n",
        "display(df_test.describe(include=[np.number]))\n",
        "\n",
        "print(\"TEST — категориальные\")\n",
        "display(df_test.describe(include=[\"object\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Вывод:** Распределения train и test похожи. Медианы и среднее близки. Категориальные признаки имеют доминирующие категории\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vF0yfzMOkEn8"
      },
      "outputs": [],
      "source": [
        "assert df_train.shape[0] == 5840"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmV784QWZOpO"
      },
      "source": [
        "## **Визуализации (1 балл + 0.5 бонус)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p2L60ngZueT"
      },
      "source": [
        "Визуализация данных — важный шаг в работе. Визуализировать данные необходимо, например, чтобы:\n",
        "\n",
        "- Оценить распределения признаков самих по себе (это может натоклнуть вас на мысли о модели, которую можно использовать)\n",
        "- Сравнить распределения на `train` и `test` — чтобы проверить, насколько информация, на которой вы будете обучаться согласуется с той, на которой модель должна работать\n",
        "- Оценить есть ли явная связь признаков с целевой переменной\n",
        "\n",
        "**Важно:**\n",
        "\n",
        "Если распределения на `train` и `test` не совпадают, это не значит, что нужно перемешивать данные! Более корректно актуализировать задачу и уточнить, а не устарели ли данные `train`. Также полезным может быть собрать новую тестовую выборку, смешав те, что имеются сейчас.\n",
        "\n",
        "**Если вы будете подгонять распределения, то можете встретиться с переобучением!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNjHoAt7nlOa"
      },
      "source": [
        "### **Задание 6 (0.5 балла)**\n",
        "\n",
        "Шаг 1.\n",
        "- [ ] Воспользуйтесь `pairplot` из библиотеки `seabron`, чтобы визуализировать попарные распределения числовых признаков для `train`\n",
        "- [ ] По полученному графику ответьте на вопросы:\n",
        " - Можно ли предположить на основе распределений связь признаков с целевой переменной?\n",
        " - Можно ли предположить на основе распределений выдвинуть гипотезу о корреляциях признаков?\n",
        "\n",
        "Шаг 2.\n",
        "\n",
        "- [ ] Постройте pairplot по тестовым данным\n",
        "- [ ] Ответьте на вопрос \"Похожими ли оказались совокупности при разделении на трейн и тест?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0car89hFaby1"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "for name, df in [(\"TRAIN\", df_train), (\"TEST\", df_test)]:\n",
        "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    g = sns.pairplot(df[num_cols], diag_kind=\"kde\", plot_kws={\"alpha\": 0.6, \"s\": 10})\n",
        "    g.fig.suptitle(name, y=1.02)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Nrf9A_Mohgz"
      },
      "source": [
        "**Ответ:** Да. По pairplot видно, что selling_price заметно связан с year, engine и max_power (чем новее авто и выше характеристики, тем выше цена), а с km_driven связь слабая отрицательная. Также можно выдвинуть гипотезы о корреляциях между признаками: engine и max_power сильно положительно коррелируют между собой, year отрицательно связан с km_driven (старые машины обычно имеют больший пробег)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G4nG3GWoniC"
      },
      "source": [
        "### **Задание 7 (0.5 балла)**\n",
        "\n",
        "И так, вы выдвинули гипотезы о наличии связи. Теперь давайте оценим эту связь в числах.\n",
        "\n",
        "**Задание:**\n",
        "- [ ] Получите значения коэффициента корреляции Пирсона для тренировочного набора данных при помощи `pd.corr()`\n",
        "- [ ] По полученным корреляциям постройте тепловую карту (`heatmap` из бибилотеки seaborn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E99LVAN2fMVH"
      },
      "outputs": [],
      "source": [
        "num = df_train.select_dtypes(include=[np.number])\n",
        "corr = num.corr(method=\"pearson\")\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", square=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w24a_oXqf12H"
      },
      "source": [
        "- [ ] Ответьте на вопросы:\n",
        " - Какие 2 признака наименее скоррелированы между собой?\n",
        " - Между какими наблюдается довольно сильная положительная линейная зависимость?\n",
        " - Правильно ли, опираясь на данные, утверждать, что чем меньше год, тем, скорее всего, больше километров проехала машина к дате продажи?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asliCDvapsEe"
      },
      "source": [
        "**Ответ:** Наименее связаны между собой year и engine, корреляция почти нулевая. Сильная положительная связь есть между selling_price и max_power, также заметна между engine и max_power. Утверждать, что чем меньше год выпуска, тем больше пробег, в целом можно: между year и km_driven есть заметная отрицательная связь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru1In410pieq"
      },
      "source": [
        "### **Бонус (0.5 балла)**\n",
        "\n",
        "Если вам кажется, что мы не попросили вас нарисовать какие-то очень важные зависимости, нарисуйте их **и поясните.**\n",
        "\n",
        "- Каждая дополнительная визуализация может принести до 0.25 баллов при условии, что она обоснована."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwlwJhDIp_2L"
      },
      "outputs": [],
      "source": [
        "c = corr.where(~np.eye(corr.shape[0], dtype=bool)).stack()\n",
        "\n",
        "least_pair = c.abs().idxmin()\n",
        "least_val = float(c.loc[least_pair])\n",
        "\n",
        "strong_pair = c.idxmax()\n",
        "strong_val = float(c.max())\n",
        "\n",
        "year_km = float(corr.loc[\"year\", \"km_driven\"]) if {\"year\", \"km_driven\"} <= set(corr.columns) else None\n",
        "\n",
        "print(\"Наименее скоррелированы:\", least_pair, \"corr=\", least_val)\n",
        "print(\"Сильная положительная связь:\", strong_pair, \"corr=\", strong_val)\n",
        "print(\"corr(year, km_driven) =\", year_km)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS2CQ1LzrP_U"
      },
      "source": [
        "# **Часть 2 | Модель только на вещественных признаках**\n",
        "\n",
        "В этой части вам предстоит обучить модель только на вещественных признаках. Почему только на них?\n",
        "\n",
        "Чем больше признаковое пространство — чем сложнее модель. А чем модель проще — тем лучше для скорости работы и интерпретации признаков.\n",
        "\n",
        "За задания этой части вы можете набрать 1.25 балла;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrsL99SsqWIz"
      },
      "source": [
        "### **Задание 8 (0.05 балла)**\n",
        "\n",
        "Сделайте тренировочный и тестовый наборы. Сделайте на тренировочный и тестовый наборы. Она уже даны, достаточно просто отделить целевой признак Перед разбиением создайте копию датафрейма, который будет хранить только вещественные признаки и используйте его (то есть категориальные столбцы (все, кроме seats) необходимо удалить).\n",
        "\n",
        "В переменные y_train и y_test запишите значения целевых переменных. Используйте уже имеющиеся данные train и test при разбиении. Если считаете уместным применить какую-то более хитрую технику разбиения — примените, но опишите, зачем."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGxjJSSUg2na"
      },
      "outputs": [],
      "source": [
        "target = \"selling_price\"\n",
        "\n",
        "y_train = df_train[target].copy()\n",
        "y_test = df_test[target].copy()\n",
        "\n",
        "X_train = df_train.drop(columns=[target]).select_dtypes(include=[np.number]).copy()\n",
        "X_test = df_test.drop(columns=[target]).select_dtypes(include=[np.number]).copy()\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyMyARKem5wl"
      },
      "outputs": [],
      "source": [
        "X_train.columns.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Использованы вещественные признаки:\n",
        "\n",
        "year - год выпуска автомобиля, km_driven - пробег, mileage - расход топлива, engine - объем двигателя, max_power - мощность двигателя, seats - количество мест"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKRmqiJ5rbSx"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "medians = X_train.median()\n",
        "X_train = X_train.fillna(medians)\n",
        "X_test = X_test.fillna(medians)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_train = model.predict(X_train)\n",
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred_train)\n",
        "r2_test = r2_score(y_test, y_pred_test)\n",
        "\n",
        "r2_train, r2_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5b4TfLtq-FC"
      },
      "source": [
        "### **Задание 9 (0.2 балла)**\n",
        "\n",
        "Построим нашу первую модель!\n",
        "- [ ] Обучите классическую линейную регрессию с дефолтными параметрами. Посчтитайте $R^2$ и $MSE$ для трейна и для теста.\n",
        "- [ ] Сделайте выводы по значениям метрик качества.\n",
        "\n",
        "**Примечание:**\n",
        "\n",
        "Здесь и далее $R^2$ и $MSE$ для трейна и для теста выводите везде, где требуется обучать модели, даже если в явном виде этого не просят. Иначе непонятно, как понять, насколько успешны наши эксперименты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVYXaeTgrb3d"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error as MSE\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "pred_tr = model.predict(X_train)\n",
        "pred_te = model.predict(X_test)\n",
        "\n",
        "r2_tr = r2_score(y_train, pred_tr)\n",
        "r2_te = r2_score(y_test, pred_te)\n",
        "mse_tr = MSE(y_train, pred_tr)\n",
        "mse_te = MSE(y_test, pred_te)\n",
        "\n",
        "r2_tr, r2_te, mse_tr, mse_te"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Вывод:** Значения R² на train и test почти одинаковые (~0.59), явного переобучения нет. Модель объясняет около 59% вариации цены. Качество среднее, но стабильное. MSE на тесте выше, чем на трейне, что ожидаемо, разрыв умеренный, модель обобщается нормально"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpQ8EG2Uk_Dn"
      },
      "source": [
        "### **Задание 10 (0.15 балла)**\n",
        "\n",
        "Всегда есть место совершенству. Поэтому давайте попробуем улучшить модель. При помощи стандартизации признаков.\n",
        "\n",
        "- [ ] Стандартизируйте значения в тренировочных и тестовых данных. Стандартизатор **обучайте только на `train`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6FB80C2rciK"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error as MSE\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_sc = scaler.fit_transform(X_train)\n",
        "X_test_sc = scaler.transform(X_test)\n",
        "\n",
        "model_sc = LinearRegression()\n",
        "model_sc.fit(X_train_sc, y_train)\n",
        "\n",
        "pred_tr = model_sc.predict(X_train_sc)\n",
        "pred_te = model_sc.predict(X_test_sc)\n",
        "\n",
        "r2_tr = r2_score(y_train, pred_tr)\n",
        "r2_te = r2_score(y_test, pred_te)\n",
        "mse_tr = MSE(y_train, pred_tr)\n",
        "mse_te = MSE(y_test, pred_te)\n",
        "\n",
        "r2_tr, r2_te, mse_tr, mse_te"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQZi8LYVmiPv"
      },
      "source": [
        "### **Задание 11 (0.1 балла)**\n",
        "\n",
        "Хотя стандартизация не помогла сильно прибавить в качестве она открыла возможность интерпретировать важность признаков в модели. Правило интерпретации такое:\n",
        "\n",
        "Чем больше коэффициент $\\beta_i$ по модулю, тем важнее признак.\n",
        "\n",
        "**Ответьте на вопрос:**\n",
        "\n",
        "- [ ] Какой признак оказался наиболее информативным в предсказании цены?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9onBNrhmt1r"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "coef = pd.Series(model_sc.coef_, index=X_train.columns).sort_values(key=np.abs, ascending=False)\n",
        "coef.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Ответ:** Наиболее информативным признаком оказался max_power, так как у него наибольший по модулю коэффициент в стандартизированной линейной модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BR3XLXUsm1q"
      },
      "source": [
        "### **Задание 12 (0.25 балла)**\n",
        "\n",
        "Попробуем улучшить нашу модель с помощью применения регуляризации. Для этого воспльзуемся `Lasso` регрессией.  Кроме того, попробуйте использовать её теоретическое свойство отбора признаков, за счет зануления незначимых коэффициентов.\n",
        "\n",
        "**Задание:**\n",
        "\n",
        "- [ ] Обучите Lasso регрессию на тренировочном наборе данных с нормализованными признаками. Оцените её качество\n",
        "- [ ] Проверьте, занулила ли L1-регуляризация с параметрами по умолчанию какие-нибудь веса? Предположите почему."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhR5eajPn0kl"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import r2_score, mean_squared_error as MSE\n",
        "\n",
        "lasso = Lasso(random_state=42)\n",
        "lasso.fit(X_train_sc, y_train)\n",
        "\n",
        "pred_tr = lasso.predict(X_train_sc)\n",
        "pred_te = lasso.predict(X_test_sc)\n",
        "\n",
        "r2_tr, r2_te, mse_tr, mse_te = (\n",
        "    r2_score(y_train, pred_tr),\n",
        "    r2_score(y_test, pred_te),\n",
        "    MSE(y_train, pred_tr),\n",
        "    MSE(y_test, pred_te),\n",
        ")\n",
        "\n",
        "zeros = (lasso.coef_ == 0).sum()\n",
        "r2_tr, r2_te, mse_tr, mse_te, zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBJKIp6FouYw"
      },
      "outputs": [],
      "source": [
        "zeros, lasso.alpha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYWLInilqQTE"
      },
      "source": [
        "### **Задание 13 Финальный рывок (0.5 балла)**\n",
        "\n",
        "До этого мы с вами использовали `train` для обучения и `test` для прогнозирования. Но у нас есть ещё одна задача — подобрать оптимальные параметры модели. Для этого используем кросс-валидацию, описанную на семинарах.\n",
        "\n",
        "Кроме того, выжмем максимум из модификаций регрессии. Построим `ElasticNet`. И сделаем всё по порядку.\n",
        "\n",
        "**Ваша задача 1:**\n",
        "\n",
        "- [ ] Перебором по сетке (c 10-ю фолдами) подберите оптимальные параметры для Lasso-регрессии. Вам пригодится класс [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).\n",
        "- [ ] Ответьте на вопросы:\n",
        " - Сколько грид-сёрчу пришлось обучать моделей?\n",
        " - Какой коэффициент регуляризации у лучшей из перебранных моделей? Занулились ли какие-нибудь из весов при такой регуляризации?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdGQ6CvApr_P"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "lasso = Lasso(max_iter=20000, random_state=42)\n",
        "\n",
        "param_grid = {\"alpha\": np.logspace(-4, 2, 25)}\n",
        "gs_lasso = GridSearchCV(lasso, param_grid=param_grid, cv=10, scoring=\"r2\", n_jobs=-1)\n",
        "gs_lasso.fit(X_train_sc, y_train)\n",
        "\n",
        "best_lasso = gs_lasso.best_estimator_\n",
        "n_models_lasso = len(gs_lasso.cv_results_[\"params\"])\n",
        "best_alpha = gs_lasso.best_params_[\"alpha\"]\n",
        "zeros_lasso = int((best_lasso.coef_ == 0).sum())\n",
        "\n",
        "n_models_lasso, best_alpha, zeros_lasso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Для Lasso было обучено 25 моделей (по числу значений alpha), лучшая модель имеет alpha ≈ 100, при этом ни один коэффициент не занулился, так как оптимальная регуляризация оказалась слишком слабой для отбора признаков"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05579aJCuY2A"
      },
      "source": [
        "**Ваша задача 2:**\n",
        "\n",
        "- [ ] Перебором по сетке (c 10-ю фолдами) подберите оптимальные параметры для [ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html) регрессии.\n",
        "- [ ] Ответьте на вопрос:\n",
        " - Сколько грид-сёрчу пришлось обучать моделей?\n",
        " - Какие гиперпараметры соответствуют лучшей (по выбранной метрике качества) из перебранных моделей?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3e5MGZMoeCR"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "enet = ElasticNet(max_iter=20000, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    \"alpha\": np.logspace(-4, 2, 25),\n",
        "    \"l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9, 1.0],\n",
        "}\n",
        "gs_enet = GridSearchCV(enet, param_grid=param_grid, cv=10, scoring=\"r2\", n_jobs=-1)\n",
        "gs_enet.fit(X_train_sc, y_train)\n",
        "\n",
        "n_models_enet = len(gs_enet.cv_results_[\"params\"])\n",
        "best_params_enet = gs_enet.best_params_\n",
        "\n",
        "n_models_enet, best_params_enet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Для ElasticNet было обучено 150 моделей (25 значений alpha × 6 значений l1_ratio), лучшая модель соответствует alpha ≈ 0.316 и l1_ratio = 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2y-_PCHrevF"
      },
      "source": [
        "# **Часть 3| Добавляем категориальные фичи**\n",
        "\n",
        "Попробуем для улучшения модели дать ей больше признаков. Добавим категориальные фичи.\n",
        "\n",
        "За эту часть можно набрать 0.75 основных балла и 0.25 бонусных.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frLASc5L8Tu5"
      },
      "source": [
        "**Задание 14 (0.1 балла)** Проанализируйте столбец `name`. Очевидно, что эта переменная является категориальной, однако категорий в ней много.\n",
        "\n",
        "В этом домашнем задании мы предлагаем удалить его.\n",
        "\n",
        "**Ваша задача:**\n",
        "- [ ] Удалить столбец`name`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsXiFjaFrng-"
      },
      "outputs": [],
      "source": [
        "target = \"selling_price\"\n",
        "\n",
        "X_train_cat = df_train.drop(columns=[target, \"name\"]).copy()\n",
        "X_test_cat  = df_test.drop(columns=[target, \"name\"]).copy()\n",
        "y_train_cat = df_train[target].copy()\n",
        "y_test_cat  = df_test[target].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hF3g5g7vodJ"
      },
      "source": [
        "В другом случае, конечно, мы могли бы предобработать данный столбец. В качестве бонуса предлагаем вам придумать и реализовать алгоритм предобработки.\n",
        "\n",
        "**Бонус 0.25 балла**\n",
        "- [ ] Предобработайте столбец `name`, чтобы избежать его удаления. Если предобработали столбец — можно закомментировать assert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqDhrd6Q8k-S"
      },
      "outputs": [],
      "source": [
        "assert X_train_cat.shape == (5840, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyGl7KQQx_Ax"
      },
      "outputs": [],
      "source": [
        "X_train_cat.describe(include='object')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrGfeTnjv9Vx"
      },
      "source": [
        "### **Задание 15 (0.4 балла)**\n",
        "\n",
        "- [ ] Закодируйте категориалльные фичи и ``seats`` методом OneHot-кодирования. Обратите внимание, что во избежание мультиколлинеарности следует избавиться от одного из полученных столбцов при кодировании каждого признака методом OneHot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbN4yM2Frob7"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "num_cols = X_train_cat.select_dtypes(include=np.number).columns.tolist()\n",
        "cat_cols = X_train_cat.columns.difference(num_cols).tolist() + [\"seats\"]\n",
        "num_cols = [c for c in num_cols if c != \"seats\"]\n",
        "\n",
        "med = X_train_cat[num_cols].median()\n",
        "Xtr = X_train_cat.copy()\n",
        "Xte = X_test_cat.copy()\n",
        "Xtr[num_cols] = Xtr[num_cols].fillna(med)\n",
        "Xte[num_cols] = Xte[num_cols].fillna(med)\n",
        "Xtr[cat_cols] = Xtr[cat_cols].astype(\"string\").fillna(\"missing\")\n",
        "Xte[cat_cols] = Xte[cat_cols].astype(\"string\").fillna(\"missing\")\n",
        "\n",
        "ohe = OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\", sparse_output=False)\n",
        "Otr = ohe.fit_transform(Xtr[cat_cols])\n",
        "Ote = ohe.transform(Xte[cat_cols])\n",
        "\n",
        "X_train_full = pd.concat([Xtr[num_cols].reset_index(drop=True),\n",
        "                          pd.DataFrame(Otr, columns=ohe.get_feature_names_out(cat_cols))],\n",
        "                         axis=1)\n",
        "X_test_full  = pd.concat([Xte[num_cols].reset_index(drop=True),\n",
        "                          pd.DataFrame(Ote, columns=ohe.get_feature_names_out(cat_cols))],\n",
        "                         axis=1)\n",
        "\n",
        "X_train_full.shape, X_test_full.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8fI5dQT-Fvx"
      },
      "source": [
        "### **Задание 16 (0.25 балла)**\n",
        "Повторим то, что делали на прошлом шаге для моделей на вещественных признаках, однако теперь с моделью `Ridge`.\n",
        "\n",
        "\n",
        "**Ваша задача:**\n",
        "- [ ] Переберите параметр регуляризации `alpha` для гребневой (ridge) регрессии с помощью класса `GridSearchCV` В качестве параметров при объявлении GridSearchCV кроме модели укажите метрику качества $R^2$. Кроссвалидируйтесь по 10-ти фолдам.\n",
        "- [ ] Ответье на вопрос: Удалось ли улучшить качество прогнозов?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLXCtme53Oup"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "ridge = Ridge(random_state=42)\n",
        "grid = GridSearchCV(ridge, {\"alpha\": np.logspace(-4, 4, 25)}, cv=10, scoring=\"r2\", n_jobs=-1)\n",
        "grid.fit(X_train_full, y_train_cat)\n",
        "\n",
        "best_ridge = grid.best_estimator_\n",
        "r2_tr = r2_score(y_train_cat, best_ridge.predict(X_train_full))\n",
        "r2_te = r2_score(y_test_cat, best_ridge.predict(X_test_full))\n",
        "\n",
        "grid.best_params_[\"alpha\"], r2_tr, r2_te"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Ответ:** Да, качество улучшилось: R² на test стало выше, переобучения нет"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw6LOYJTL2x1"
      },
      "source": [
        "# **Часть 4. | Бизнесовая (0.5 балла)**\n",
        "\n",
        "### **Задание 17 (0.5 балла)**\n",
        "\n",
        "В мире бизнеса очень важно давать оценку качества модели понятную бизнесу, поэтому иногда заказчики приходят с кастомными метриками. Попробуем сделать такую для нашей задачи.\n",
        "\n",
        "**Описание метрики:**\n",
        "\n",
        "Среди всех предсказанных цен на авто нужно посчитать долю прогнозов, отличающихся от реальных цен на эти авто не более чем на 10% (в одну или другую сторону)\n",
        "\n",
        "**Ваша задача:**\n",
        "\n",
        "- [ ] Реализуйте метрику `business_metric`\n",
        "- [ ] Посчитайте метрику для всех обученных моделей и определеите, какая лучше всего решает задачу бизнеса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrcaGhO7MnMR"
      },
      "outputs": [],
      "source": [
        "def business_metric(y_true, y_pred):\n",
        "    return (abs(y_pred - y_true) / y_true <= 0.1).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bm_linear = business_metric(y_test, model.predict(X_test))\n",
        "bm_lasso  = business_metric(y_test, best_lasso.predict(X_test_sc))\n",
        "bm_ridge  = business_metric(y_test_cat, best_ridge.predict(X_test_full))\n",
        "\n",
        "bm_linear, bm_lasso, bm_ridge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZk-Tfr7xLsm"
      },
      "source": [
        "**Ответ:** Лучший результат по бизнес-метрике показывает Ridge (≈0.245), значит именно эта модель чаще всего предсказывает цену с ошибкой не более 10% и лучше всего решает задачу бизнеса"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Сохранение модели и артефактов\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "model_artifacts = {\n",
        "    'model': best_ridge,\n",
        "    'ohe': ohe,\n",
        "    'num_cols': num_cols,\n",
        "    'cat_cols': cat_cols,\n",
        "    'medians': med,\n",
        "    'feature_names': X_train_full.columns.tolist(),\n",
        "    'y_train': y_train_cat,\n",
        "    'X_train_full': X_train_full\n",
        "}\n",
        "\n",
        "with open('model_pipeline.pkl', 'wb') as f:\n",
        "    pickle.dump(model_artifacts, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s09c7jmxo7Ii"
      },
      "source": [
        "# **<font color=\"green\">Часть 5 | Создание интерактивного приложения на Streamlit (3 балла)</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uzGYDIXqmFO"
      },
      "source": [
        "Вам необходимо создать интерактивное приложение на Streamlit, которое будет:\n",
        "\n",
        "- Показывать основные информативные графики/гистограммы в рамках EDA (1 балл)\n",
        "- На вход запрашивать csv-файл с признаками объектов или запрашивать признаки объекта в окошках для ввода, и применять на поступивших объектах модель (1 балл)\n",
        "- Визуализировать веса обученной модели (1 балл)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmwf-ZrEKZy6"
      },
      "source": [
        "# **Часть 6 | Оформление репозитория и оценка сервиса (2 балла)**\n",
        "\n",
        "**Результаты вашей работы** необходимо разместить в своём GitHub-репозитории. В этот же репозиторий позже будет добавлена вторая часть.\n",
        "\n",
        "Под результатами первой части понимаем следующее:\n",
        "\n",
        "---\n",
        "\n",
        "### Обязательные файлы:\n",
        "\n",
        "1. **`.ipynb`-ноутбук** со всеми экспериментами:\n",
        "\n",
        "   * полный EDA,\n",
        "   * все шаги препроцессинга,\n",
        "   * обучение и сравнение моделей,\n",
        "   * сохранённые output’ы.\n",
        "\n",
        "2. **`.pickle`-файл**, содержащий:\n",
        "\n",
        "   * обученную модель (или пайплайн `scaler + model`);\n",
        "   * параметры скейлинга;\n",
        "   * любые числовые объекты, необходимые для инференса внутри Streamlit-приложения.\n",
        "\n",
        "3. **`.md`-файл с выводами** о проделанной работе:\n",
        "\n",
        "   * что было сделано (краткое описание каждого этапа);\n",
        "   * какие результаты были получены (метрики + интерпретация);\n",
        "   * что дало наибольший прирост качества;\n",
        "   * что сделать не удалось и почему (это нормально и даже полезно);\n",
        "   * **оценка разработанного сервиса**:\n",
        "\n",
        "     * насколько приложение удобно в использовании;\n",
        "     * что получилось визуализировать хорошо, а что — менее удачно;\n",
        "     * какие ограничения или проблемы вы заметили;\n",
        "     * какие улучшения планируете в следующей итерации.\n",
        "\n",
        "По результатам второй части, ждем:\n",
        "\n",
        "4. **Streamlit-приложение** (например, `app.py`), которое можно запустить командой:\n",
        "\n",
        "   ```bash\n",
        "   streamlit run app.py\n",
        "   ```\n",
        "\n",
        "**И ссылку на приложение в StreamlitHub.**\n",
        "\n",
        "В приложении должно быть:\n",
        "\n",
        "* отображение ключевых графиков EDA;\n",
        "* ввод данных (CSV или ручной ввод);\n",
        "* применение модели;\n",
        "* визуализация весов/коэффициентов.\n",
        "\n",
        "\n",
        "\n",
        "### **За что могут быть сняты баллы:**\n",
        "\n",
        "* отсутствие `.pickle` с моделью / пайплайном;\n",
        "* слабая или неполная аналитика в `.md`-файле;\n",
        "* беспорядок в ноутбуке или неясная логика вычислений;\n",
        "* отсутствие возможности запустить Streamlit-приложение."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "IsPer4g5FgRB",
        "ykzSVgN7q-xZ"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
